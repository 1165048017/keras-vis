{
    "docs": [
        {
            "location": "/", 
            "text": "Keras Visualization Toolkit\n\n\n\n\n\n\nkeras-vis is a high-level toolkit for visualizing input images via guided backprop. \nThere are several repositories out there to visualize: \n\n\n\n\nActivation maximization\n\n\nSaliency maps\n\n\nCaricaturization (deep dream)\n\n\nTexture style transfer\n\n\nNeural style transfer\n\n\n\n\nThis toolkit generalizes all of the above and image backprop problems in general as energy minimization problem.\nCompatible with both theano and tensorflow backends. \n\n\nGetting Started\n\n\nIn image backprop problems, the goal is to generate an input image that minimizes some loss function.\n\n\nVarious useful loss functions are defined in \nlosses.py\n.\nA custom loss function can be defined by implementing \nLoss\n\nclass.\n\n\nIn order to generate natural looking images, image search space is constrained using regularization penalties. \nSome common regularizers are defined in \nregularizers.py\n.\nLike loss functions, custom regularizer can be defined by implementing \n\nLoss\n class.\n\n\nSetting up an image backprop problem is easy.\n\n\nDefine weighted loss function\n\n\nfrom vis.losses import ActivationMaximization\nfrom vis.regularizers import TotalVariation, LPNorm\n\nfilter_indices = [1, 2, 3]\n\n# Tuple consists of (loss_function, weight)\n# Add regularizers as needed.\nlosses = [\n    (ActivationMaximization(keras_layer, filter_indices), 1),\n    (LPNorm(), 10),\n    (TotalVariation(), 10)\n]\n\n\n\n\nConfigure optimizer to minimize weighted loss\n\n\nfrom vis.optimizer import Optimizer\n\noptimizer = Optimizer(img_input_layer, losses)\nopt_img, grads = optimizer.minimize()\n\n\n\n\nQuick start\n\n\nSee examples for various visualizations in \nexamples/\n folder.\n\n\nVisualizations\n\n\nNeural nets are black boxes. How can we be sure that they are learning the right thing? If the neural net generates a\nwrong prediction, how could we diagnose the issue? In the recent years, several approaches for understanding and \nvisualizing Convolutional Networks have been developed in the literature.\n\n\nConv filter visualization\n\n\nEach conv layer has several learned 'template matching' filters that maximize their output when a similar template \npattern is found in the input image. This makes the first conv net layer highly interpretable by simply visualizing \ntheir weights as it is operating over raw pixels.\n\n\nSubsequent conv filters operate over the outputs of previous conv filters (which indicate the presence or absence of \nsome templates), so visualizing them directly is not very interpretable.\n\n\nOne way of interpreting them is to generate an input image that maximizes the filter output. With keras-vis, setting\nthis up is easy. Lets visualize the second conv layer of vggnet (named as 'block1_conv2').\n\n\nimport cv2\nfrom vis.utils.vggnet import VGG16\nfrom vis.visualization import visualize_activation\n\n# Build the VGG16 network with ImageNet weights\nmodel = VGG16(weights='imagenet', include_top=True)\nprint('Model loaded.')\n\n# The name of the layer we want to visualize\n# (see model definition in vggnet.py)\nlayer_name = 'block1_conv2'\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n\nvis_img = visualize_activation(model.input, layer_dict[layer_name])\ncv2.imshow(layer_name, vis_img)\ncv2.waitKey(0)\n\n\n\n\nThis generates the following stitched image representing input image(s) that maximize the filter_idx output.\nThey mostly seem to match for specific color and directional patterns.\n\n\n\n\nLets visualize the remaining conv filters (first few) by iterating over different \nlayer_name\n values.\n\n\nblock2_conv2: random sample of the 128 filters\n\n\n\n\nblock3_conv3: random sample of the 256 filters\n\n\n\n\nblock3_conv4: random sample of the 512 filters\n\n\n\n\nblock3_conv5: random sample of the 512 filters\n\n\n\n\nSome of the 'block5_conv3' filters failed to converge. This is because regularization losses (total variation and \nLP norm) are overtaking activation maximization loss (set \nverbose=True\n to observe). \n\n\nWhenever activation maximization fails to converge, total variation regularization is the typical culprit. \nIt is easier to minimize total variation from a random image (just have to create blobbier color structures), \nand this sets the input image in a bad local minima that makes it difficult to optimize for activation maximization. \nWe can turn off total variation by setting \ntv_weight=0\n. This generates most of the previously unconverged filters.\n\n\n\n\nBy this layer, we can clearly notice templates for complex patterns such as flower buds / corals \n(filters 67, 84 respectively). Notice that images are not as coherent due to lack of total variation loss.\n\n\nA good strategy in these situations might be to seed the optimization with image output generated via tv_weight=0\nand add the tv_weight back. Lets specifically look at filter 67.\n\n\nlayer_name = 'block5_conv3'\n\nno_tv_seed_img = visualize_activation(model.input, layer_dict[layer_name], filter_indices=[67],\n                                      tv_weight=0, verbose=True)\npost_tv_img = visualize_activation(model.input, layer_dict[layer_name], filter_indices=[67],\n                                   tv_weight=1, seed_img=no_tv_seed_img, verbose=True, max_iter=300)\ncv2.imshow(layer_name, post_tv_img)\ncv2.waitKey(0)\n\n\n\n\nAs expected, this generates a blobbier and smoother image:\n\n\n\n\nDense layer visualization\n\n\nGiven an input image, conv net can classify whether it is a cat, bird etc. How can we be sure that it is capturing \nthe correct notion of what it means to be a bird? Suppose that all the training images of 'bird' class contains a tree\nwith leaves. How do we know that the conv net is indeed 'looking' at the bird as opposed to leaves and classifying it \nas a bird?\n\n\nOne way to peer into the black box is to ask the reverse question - Generate an input image that maximizes the final\n\nDense\n layer output corresponding to bird class. Lets try this for 'ouzel' (imagenet output category: 20)\n\n\nimport cv2\nfrom vis.utils.vggnet import VGG16\nfrom vis.visualization import visualize_activation\n\n# Build the VGG16 network with ImageNet weights\nmodel = VGG16(weights='imagenet', include_top=True)\nprint('Model loaded.')\n\n# The name of the layer we want to visualize\n# (see model definition in vggnet.py)\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\nlayer_name = 'predictions'\n\n# Generate three different images of the same output index.\nimg = visualize_activation(model.input, layer_dict[layer_name],\n                           filter_indices=[20, 20, 20], max_iter=500)\ncv2.imshow(layer_name, img)\ncv2.waitKey(0)\n\n\n\n\nand out comes this..\n\n\n\n\nNot only has the conv net captured what it means to be an ouzel, but it also seems to encode for different orientations \nand scales, a further proof of rotational and scale invariance. \n\n\nLets do this for a few more random imagenet categories.\n\n\n\n\nIf you squint really hard, we can sort of see that most images are more or less accurate representations of the \ncorresponding class.\n\n\nYou might notice that in most of these visualizations, the same pattern tends to repeat all over the image \nwith different orientations and scales. Why is this the case? If you think about it, it is essentially the consequence\nof activation maximization loss. Multiple copies of 'template pattern' all over the image should increase the output value.\n\n\nIf we want more natural looking images, we need a better 'natural image' regularizer that penalizes this sort of \nbehavior. Instead of hand crafting the regularizer, we can use the negative of 'discriminator' output probability \n(since we want to maximize probability that the image is real) of a generative adversarial network (GAN). \n\n\nSee this article for details about GANs in general: \nUnsupervised Representation Learning with Deep Convolutional \nGenerative Adversarial Networks\n\n\nGAN regularizer is currently a work in progress. Check back in a few days.\n\n\nAt this point, it might be fun to see the effect of total variation regularizer. The following images are generated with\n\ntv_weight=0\n\n\n\n\nTotal variation regularizer definitely helps in creating more natural looking images. I am excited to see what\na GAN discriminator could do.\n\n\nSaliency Maps\n\n\nMore will be added soon (WIP...)\n\n\nGenerating animated gif of optimization progress\n\n\nIt is possible to generate an animated gif of optimization progress. Below is an example for activation maximization\nof 'ouzel' class (output_index: 20).\n\n\nfrom vis.utils.vggnet import VGG16\nfrom vis.optimizer import Optimizer\nfrom vis.losses import ActivationMaximization\nfrom vis.regularizers import TotalVariation, LPNorm\n\n# Build the VGG16 network with ImageNet weights\nmodel = VGG16(weights='imagenet', include_top=True)\nprint('Model loaded.')\n\n# The name of the layer we want to visualize\n# (see model definition in vggnet.py)\nlayer_name = 'predictions'\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\noutput_class = [20]\n\nlosses = [\n    (ActivationMaximization(layer_dict[layer_name], output_class), 1),\n    (LPNorm(), 10),\n    (TotalVariation(), 1)\n]\nopt = Optimizer(model.input, losses)\n\n# Jitter is used as a regularizer to create crisper images, but it makes gif animation ugly.\nopt.minimize(max_iter=500, verbose=True, jitter=0,\n             progress_gif_path='opt_progress')", 
            "title": "Home"
        }, 
        {
            "location": "/#keras-visualization-toolkit", 
            "text": "keras-vis is a high-level toolkit for visualizing input images via guided backprop. \nThere are several repositories out there to visualize:    Activation maximization  Saliency maps  Caricaturization (deep dream)  Texture style transfer  Neural style transfer   This toolkit generalizes all of the above and image backprop problems in general as energy minimization problem.\nCompatible with both theano and tensorflow backends.", 
            "title": "Keras Visualization Toolkit"
        }, 
        {
            "location": "/#getting-started", 
            "text": "In image backprop problems, the goal is to generate an input image that minimizes some loss function.  Various useful loss functions are defined in  losses.py .\nA custom loss function can be defined by implementing  Loss \nclass.  In order to generate natural looking images, image search space is constrained using regularization penalties. \nSome common regularizers are defined in  regularizers.py .\nLike loss functions, custom regularizer can be defined by implementing  Loss  class.  Setting up an image backprop problem is easy.  Define weighted loss function  from vis.losses import ActivationMaximization\nfrom vis.regularizers import TotalVariation, LPNorm\n\nfilter_indices = [1, 2, 3]\n\n# Tuple consists of (loss_function, weight)\n# Add regularizers as needed.\nlosses = [\n    (ActivationMaximization(keras_layer, filter_indices), 1),\n    (LPNorm(), 10),\n    (TotalVariation(), 10)\n]  Configure optimizer to minimize weighted loss  from vis.optimizer import Optimizer\n\noptimizer = Optimizer(img_input_layer, losses)\nopt_img, grads = optimizer.minimize()", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#quick-start", 
            "text": "See examples for various visualizations in  examples/  folder.", 
            "title": "Quick start"
        }, 
        {
            "location": "/#visualizations", 
            "text": "Neural nets are black boxes. How can we be sure that they are learning the right thing? If the neural net generates a\nwrong prediction, how could we diagnose the issue? In the recent years, several approaches for understanding and \nvisualizing Convolutional Networks have been developed in the literature.", 
            "title": "Visualizations"
        }, 
        {
            "location": "/#conv-filter-visualization", 
            "text": "Each conv layer has several learned 'template matching' filters that maximize their output when a similar template \npattern is found in the input image. This makes the first conv net layer highly interpretable by simply visualizing \ntheir weights as it is operating over raw pixels.  Subsequent conv filters operate over the outputs of previous conv filters (which indicate the presence or absence of \nsome templates), so visualizing them directly is not very interpretable.  One way of interpreting them is to generate an input image that maximizes the filter output. With keras-vis, setting\nthis up is easy. Lets visualize the second conv layer of vggnet (named as 'block1_conv2').  import cv2\nfrom vis.utils.vggnet import VGG16\nfrom vis.visualization import visualize_activation\n\n# Build the VGG16 network with ImageNet weights\nmodel = VGG16(weights='imagenet', include_top=True)\nprint('Model loaded.')\n\n# The name of the layer we want to visualize\n# (see model definition in vggnet.py)\nlayer_name = 'block1_conv2'\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n\nvis_img = visualize_activation(model.input, layer_dict[layer_name])\ncv2.imshow(layer_name, vis_img)\ncv2.waitKey(0)  This generates the following stitched image representing input image(s) that maximize the filter_idx output.\nThey mostly seem to match for specific color and directional patterns.   Lets visualize the remaining conv filters (first few) by iterating over different  layer_name  values.", 
            "title": "Conv filter visualization"
        }, 
        {
            "location": "/#block2_conv2-random-sample-of-the-128-filters", 
            "text": "", 
            "title": "block2_conv2: random sample of the 128 filters"
        }, 
        {
            "location": "/#block3_conv3-random-sample-of-the-256-filters", 
            "text": "", 
            "title": "block3_conv3: random sample of the 256 filters"
        }, 
        {
            "location": "/#block3_conv4-random-sample-of-the-512-filters", 
            "text": "", 
            "title": "block3_conv4: random sample of the 512 filters"
        }, 
        {
            "location": "/#block3_conv5-random-sample-of-the-512-filters", 
            "text": "Some of the 'block5_conv3' filters failed to converge. This is because regularization losses (total variation and \nLP norm) are overtaking activation maximization loss (set  verbose=True  to observe).   Whenever activation maximization fails to converge, total variation regularization is the typical culprit. \nIt is easier to minimize total variation from a random image (just have to create blobbier color structures), \nand this sets the input image in a bad local minima that makes it difficult to optimize for activation maximization. \nWe can turn off total variation by setting  tv_weight=0 . This generates most of the previously unconverged filters.   By this layer, we can clearly notice templates for complex patterns such as flower buds / corals \n(filters 67, 84 respectively). Notice that images are not as coherent due to lack of total variation loss.  A good strategy in these situations might be to seed the optimization with image output generated via tv_weight=0\nand add the tv_weight back. Lets specifically look at filter 67.  layer_name = 'block5_conv3'\n\nno_tv_seed_img = visualize_activation(model.input, layer_dict[layer_name], filter_indices=[67],\n                                      tv_weight=0, verbose=True)\npost_tv_img = visualize_activation(model.input, layer_dict[layer_name], filter_indices=[67],\n                                   tv_weight=1, seed_img=no_tv_seed_img, verbose=True, max_iter=300)\ncv2.imshow(layer_name, post_tv_img)\ncv2.waitKey(0)  As expected, this generates a blobbier and smoother image:", 
            "title": "block3_conv5: random sample of the 512 filters"
        }, 
        {
            "location": "/#dense-layer-visualization", 
            "text": "Given an input image, conv net can classify whether it is a cat, bird etc. How can we be sure that it is capturing \nthe correct notion of what it means to be a bird? Suppose that all the training images of 'bird' class contains a tree\nwith leaves. How do we know that the conv net is indeed 'looking' at the bird as opposed to leaves and classifying it \nas a bird?  One way to peer into the black box is to ask the reverse question - Generate an input image that maximizes the final Dense  layer output corresponding to bird class. Lets try this for 'ouzel' (imagenet output category: 20)  import cv2\nfrom vis.utils.vggnet import VGG16\nfrom vis.visualization import visualize_activation\n\n# Build the VGG16 network with ImageNet weights\nmodel = VGG16(weights='imagenet', include_top=True)\nprint('Model loaded.')\n\n# The name of the layer we want to visualize\n# (see model definition in vggnet.py)\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\nlayer_name = 'predictions'\n\n# Generate three different images of the same output index.\nimg = visualize_activation(model.input, layer_dict[layer_name],\n                           filter_indices=[20, 20, 20], max_iter=500)\ncv2.imshow(layer_name, img)\ncv2.waitKey(0)  and out comes this..   Not only has the conv net captured what it means to be an ouzel, but it also seems to encode for different orientations \nand scales, a further proof of rotational and scale invariance.   Lets do this for a few more random imagenet categories.   If you squint really hard, we can sort of see that most images are more or less accurate representations of the \ncorresponding class.  You might notice that in most of these visualizations, the same pattern tends to repeat all over the image \nwith different orientations and scales. Why is this the case? If you think about it, it is essentially the consequence\nof activation maximization loss. Multiple copies of 'template pattern' all over the image should increase the output value.  If we want more natural looking images, we need a better 'natural image' regularizer that penalizes this sort of \nbehavior. Instead of hand crafting the regularizer, we can use the negative of 'discriminator' output probability \n(since we want to maximize probability that the image is real) of a generative adversarial network (GAN).   See this article for details about GANs in general:  Unsupervised Representation Learning with Deep Convolutional \nGenerative Adversarial Networks  GAN regularizer is currently a work in progress. Check back in a few days.  At this point, it might be fun to see the effect of total variation regularizer. The following images are generated with tv_weight=0   Total variation regularizer definitely helps in creating more natural looking images. I am excited to see what\na GAN discriminator could do.", 
            "title": "Dense layer visualization"
        }, 
        {
            "location": "/#saliency-maps", 
            "text": "", 
            "title": "Saliency Maps"
        }, 
        {
            "location": "/#more-will-be-added-soon-wip", 
            "text": "", 
            "title": "More will be added soon (WIP...)"
        }, 
        {
            "location": "/#generating-animated-gif-of-optimization-progress", 
            "text": "It is possible to generate an animated gif of optimization progress. Below is an example for activation maximization\nof 'ouzel' class (output_index: 20).  from vis.utils.vggnet import VGG16\nfrom vis.optimizer import Optimizer\nfrom vis.losses import ActivationMaximization\nfrom vis.regularizers import TotalVariation, LPNorm\n\n# Build the VGG16 network with ImageNet weights\nmodel = VGG16(weights='imagenet', include_top=True)\nprint('Model loaded.')\n\n# The name of the layer we want to visualize\n# (see model definition in vggnet.py)\nlayer_name = 'predictions'\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\noutput_class = [20]\n\nlosses = [\n    (ActivationMaximization(layer_dict[layer_name], output_class), 1),\n    (LPNorm(), 10),\n    (TotalVariation(), 1)\n]\nopt = Optimizer(model.input, losses)\n\n# Jitter is used as a regularizer to create crisper images, but it makes gif animation ugly.\nopt.minimize(max_iter=500, verbose=True, jitter=0,\n             progress_gif_path='opt_progress')", 
            "title": "Generating animated gif of optimization progress"
        }
    ]
}